{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2w4EXQjLDeBtA975+VJUt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1306minyoung/data/blob/main/7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "심층신경망\n",
        "\n",
        "- 2개이상의 츠을 포함한 신경망\n",
        "- 종종 다층인공신경망, 심층신경망, 딥러닝을 같은 의미로 사용"
      ],
      "metadata": {
        "id": "CcMH3z-VN3hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RCH692SOAPF",
        "outputId": "db63d487-3769-4cb2-a890-0c3ec7a57b86"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_scaled = train_input/255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nzeu4sMKOMsi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**은닉층**\n",
        "\n",
        "입력층과 출력층 사이에 있느 모든 층\n",
        "\n",
        "출력층에서는 소프트맥스나 시그모이드 함수를 써야함\n",
        "\n",
        "그러나 은닉층은 활성화 함수의 선택이 자유로움\n",
        "\n",
        "**왜 은닉층에 활성화 함수를 적용?**\n",
        "\n",
        "활성화 함수 없이 은닉층만 있다면 의미가 없기 때문\n",
        "\n",
        "은닉층에서 선형적인 산술 계산만 수행한다면 수행 역할이 없는 셈.\n",
        "\n",
        "선형 계산을 적당하게 비선형적으로 비틀어 주어야 한다. 그래야 다음 층의 계산과 단순히 합쳐지지 않고 나름의 역할을 할 수 있는 것."
      ],
      "metadata": {
        "id": "pigTZV49O3L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
        "#dense1: 은닉층, 100개의 뉴런을 가진 밀집층. 활성화 함수를 시그모이드로 지정하고 입력의 크기는(784,)로 지정"
      ],
      "metadata": {
        "id": "9DWyWV4BOscy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense2 = keras.layers.Dense(10, activation='softmax')\n",
        "#dense2: 출력층. 10개의 클래스를 분류하므로 10개의 뉴런을 둠. 활성화 함수는 소프트맥스."
      ],
      "metadata": {
        "id": "tK6Mcev_QIFI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([dense1, dense2])"
      ],
      "metadata": {
        "id": "itX0awriQYw_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "summary() : 층에 대한 유용한 정보 얻을 수 있음\n",
        "\n",
        "param 부분: 픽셀784+1개가 은닉층 100개와 연결되니까 785*100이라서 78500, 은닉층 뉴런 100개+1개가 10개의 출력층 뉴런과 모두 연결되니까 101*10이라서 1010\n",
        "(1개씩 왜 더하냐? -> 뉴런마다 한개씩 절편이 있어서)"
      ],
      "metadata": {
        "id": "LoXNkyR5QfwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ebZc8vvQZYJ",
        "outputId": "a620710e-e1ee-4ad1-ddea-829e4aaf8b52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##층을 추가하는 방법\n",
        "\n",
        "따로 Dense 클래스를 추가하지 않고 Sequential클래스의 생성자 안에서 바로 dense 클래스의 객체를 만듦"
      ],
      "metadata": {
        "id": "BD6poqDWSA7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "    keras.layers.Dense(10, activation='softmax', name='output')\n",
        "], name='패션 MNIST 모델')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJWDAvQSQY7N",
        "outputId": "694595a2-6050-4637-a503-3fd9254bd377"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"패션 MNIST 모델\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "편리하지만 아주 많은 층을 추가하려면 Sequential 클래스의 생성자가 매우 길어지고 조건에 따라 층을 추가할 수 없음"
      ],
      "metadata": {
        "id": "8jY0doCtSq4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-H0oJLqRn3e",
        "outputId": "70d58d9e-421d-4fef-e667-aca36127f912"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(None, 100)인 이유. 첫번째 차원은 샘플의 개수를 나타내는데, 샘플개수가 아직 정의되어 있지 않기 때문에 그런것!"
      ],
      "metadata": {
        "id": "zcwi6rHCZQ4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 훈련\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sCfL9UoTA30",
        "outputId": "5b510a0c-d014-4f77-da51-211d0e4bacee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 11s 6ms/step - loss: 0.5687 - accuracy: 0.8062\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4116 - accuracy: 0.8512\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.3762 - accuracy: 0.8636\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3536 - accuracy: 0.8725\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3349 - accuracy: 0.8787\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7afc38641fc0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0dlsitgTF2w",
        "outputId": "a0da1a73-0668-492e-f396-0ad330bf4651"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8692\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3580542802810669, 0.8691666722297668]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##렐루 함수"
      ],
      "metadata": {
        "id": "2sY-QOrDX4aW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "활성함수를 바꿔보자\n",
        "\n",
        "초창기 인공신경망의 은닉층에 많이 사용된 함수는 시그모이드.\n",
        "\n",
        "오른쪽과 왼쪽 끝으로 갈 수록 그래프가 누워있으니까 올바른 출력을 만드는데 신속 대응 불가.\n",
        "\n",
        "특히 층이 많은 경우 심층 신경망인 경우 그 효과가 누적되어 더 어려움.\n",
        "\n",
        "그래서 이를 개선 하기 위해 다른 종류의 활성화 함수가 제안됨. -> 렐루함수!\n",
        "\n",
        "렐루함수는 입력이 양수일 때 입력을 그대로 통과시키고 음수일 경우 0으로 설정.\n",
        "\n",
        "렐루함수는 max(0,z)와 같이 쓸수 있음\n",
        "\n",
        "\n",
        "이 함수는 z가 0보다 크면 z를 출력하고 z가 0보다 작으면 0을 출력.\n",
        "\n",
        "렐루는 특히 이미지 출력에서 좋은 성능을 냄."
      ],
      "metadata": {
        "id": "5P8jSAeJTRJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Flatten층**\n",
        "\n",
        "배치 차원 제외 나머지 입력차원을 모두 일렬로 펼치는 역할만 함.\n",
        "\n",
        "데이터의 첫번째축을 배치축 또는 배치 차원이라고 부름\n",
        "\n",
        "입력에 곱해지는 가중치나 절편이 없어 성능에 기여하는 것은 없음\n",
        "\n",
        "그러나 flatten 클래스를 층처럼 입력층과 은닉층 사이에 추가하기 때문에 이를 층이라 부름"
      ],
      "metadata": {
        "id": "ubAmqllYX7ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "LOOLOAkjTQXv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePE7wUT6Ya4O",
        "outputId": "89e1928e-b92b-431a-b0bb-2fa27ed4d02c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫번째 등장하는 flatten 클래스에 포함된 모델 파라미터는 0개\n",
        "\n",
        "케라스의 flatten 층을 신경망 모델에 추가하면 입력 값의 차원 짐작 가능.\n",
        "\n",
        "케라스 API는 입력 데이터에 대한 전처리 과정을 가능하면 모델에 포함시킴"
      ],
      "metadata": {
        "id": "spCVMwiJYelk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_scaled = train_input / 255.0\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Bd9vCwf1Yc64"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzyM2AVkYz_7",
        "outputId": "b1ce09f4-9aa7-4b72-c27c-a6637811df85"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5390 - accuracy: 0.8088\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3939 - accuracy: 0.8584\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3551 - accuracy: 0.8724\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3303 - accuracy: 0.8811\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3164 - accuracy: 0.8885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7afc2672fee0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**옵티마이저**\n",
        "\n",
        "신경망의 가중치와 절편을 학습하기 위한 알고리즘 또는 방법\n",
        "\n",
        "사용할 경사 하강법 알고리즘과 그 파라미터를 지정하는 매개변수\n",
        "\n",
        "신경망에는 하이퍼파라미터가 많음\n",
        "\n",
        "추가할 은닉층의 개수, 은닉층의 뉴런개수, 활성화 함수, 층의 종류 등\n",
        "\n",
        "케라스는 다양한 종류의 경사 하강법 알고리즘을 제공해 이들을 옵티마이저라고 함"
      ],
      "metadata": {
        "id": "wgYxzP4pZfYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모멘텀 최적화**\n",
        "\n",
        "모멘텀(관성, 운동량) 조절\n",
        "\n",
        "sgd=keras.optimizers.SGD(momentum=0.9)#기본값 0\n",
        "\n",
        "새로운 가중치와 절편 계산시 과거의 가중치와 절편의 변화량을 어느정도 반영할거지 결정\n",
        "\n",
        "**네스테로프 모멘텀 최적화**\n",
        "\n",
        "모멘텀 최적화 2번 반복\n",
        "\n",
        "손실함수의 입력인 이전의 기울기 절편에 추가로 이전 속도가 더해진다."
      ],
      "metadata": {
        "id": "oHnoJAQyajfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "sgd = keras.optimizers.SGD()\n",
        "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.1)\n",
        "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
        "adagrad = keras.optimizers.Adagrad()\n",
        "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "rmsprop = keras.optimizers.RMSprop()\n",
        "model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "q8ifRIt2ZkFz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "UYXuypticfju"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)\n",
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1uGMUKUcgnc",
        "outputId": "ee668610-01dd-4315-deed-1fba346eeec5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5212 - accuracy: 0.8191\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3929 - accuracy: 0.8595\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3547 - accuracy: 0.8718\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3259 - accuracy: 0.8798\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3049 - accuracy: 0.8883\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8782\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.340666264295578, 0.878166675567627]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam : 모멘텀 최적화와 RMSprop의 장점을 접목한 것.\n",
        "\n",
        "keras.optimizers 패키지 아래에 있고, learning_rate 매개변수 기본값은 0.001임.\n",
        "\n",
        "모멘텀 최적화에 있는 그래디언트의 지수 감소 평균을 조절하기 위해 beta_1 매개변수가 있음(기본값 0.9)\n",
        "\n",
        "RMSprop에 있는 그레디언트 제곱의 지수감소 평균을 조절하기 위해 beta_2 매개변수가 있음(기본값 0.999)"
      ],
      "metadata": {
        "id": "0xy-PFsBcy_t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ECxdrWHdqfi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}